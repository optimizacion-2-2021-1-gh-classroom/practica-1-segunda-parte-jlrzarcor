{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE LINEAR CONJUGATE GRADIENT METHON (CGM)\n",
    "\n",
    "The CGM is an iterative methon for solving linear system of equations\n",
    "\n",
    "$$Ax=b$$,\n",
    "\n",
    "WHERE $A_{nxn}$ is a symetric positive define matrix. This problem can equivalent to the minimization problem:\n",
    "\n",
    "$$min \\ \\phi(x) := \\frac{1}{2} x^{T}Ax-b^{T}x$$,\n",
    "\n",
    "The gradient of $\\phi$ equals the residual of the linear system,\n",
    "\n",
    "$$\\nabla \\ \\phi(x) = Ax -b := r(x)$$\n",
    "\n",
    "in particular at $x=x_{k}$ we have\n",
    "\n",
    "$$r_{k} = Ax_{k}-b$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONJUGATED DIRECTION METHODS\n",
    "\n",
    "$$P_{i}^{T} A p_{j} = 0,  for  \\ all \\   i \\neq j$$\n",
    "\n",
    "Given a starting point $x_{0} \\in \\mathbb{R}^{n}$ and a set of conjufated directions $\\{ p_{0},p_{1},...,p_{n-1}\\}$ que can generate the sequence $\\{x_{k}\\}$\n",
    "\n",
    "\n",
    "$$x_{k+1} = x_{k} + \\alpha_{k}p_{k}$$\n",
    "\n",
    "Where\n",
    "\n",
    "$$\\alpha_{k} = - \\frac{r_{k}^{T}p_{k}}{p_{k}^{t}Ap_{K}} $$\n",
    "\n",
    "\n",
    "#### Theorem\n",
    "\n",
    "_For any $x_{0} \\in \\mathbb{R}^{n}$ the sequence $\\{x_{k}\\}$ generated be the conjugated direction algorithm, converges to the solution $x^{*}$ of the linear system in at most $n$ steps._\n",
    "\n",
    "\n",
    "\n",
    "When $A$ is diagonal qe can trsnform the prolem to minimize along the coordinate direction. We define a new variable $\\hat{x}$\n",
    "\n",
    "$$\\hat{x} = S^{-1}x$$\n",
    "\n",
    "Where $S$ is the $nxn$ matrix defined be\n",
    "\n",
    "$$S = \\left[ p_{0}\\  p_{1} ... p_{n-1} \\right] $$\n",
    "\n",
    "where $\\{ p_{0},p_{1},...,p_{n-1}\\}$ is the set of conjugated directions with respect to $A$. The quadratic $\\phi$ defined now becomes\n",
    "\n",
    "$$\\hat{\\phi}(\\hat{x}) : = \\phi(S\\hat{x}) = \\frac{1}{2}\\hat{x}^{T}(S^{T}AS)\\hat{x}-(S^{T}b)^{T}\\hat{x}$$\n",
    "\n",
    "\n",
    "\n",
    "$$r_{k+1} = r_{k} + \\alpha_{k}Ap_{k}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASIC PROPERTIES OF THE CONJUGATED GRADIENT METHOD\n",
    "\n",
    "* we can compute a new vector $p_{k}$ by using only the previous vector $p_{k-1}$\n",
    "\n",
    "$$p_{k} = -r_{k} + \\beta_{k}\\ p_{k-1}$$\n",
    "\n",
    "$p_{k-1}^{T} Ap_{k} =0$\n",
    "\n",
    "$$ \\beta_{k} =\\frac{r_{k}^{T}Ap_{k-1}}{p_{k}^{T}Ap_{k-1}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A PRACTICAL FORM OF THE CONJUGATE GRADIENT METHOD\n",
    "\n",
    "$$\\alpha_{k} = \\frac{r_{k}^{T}r_{k}}{p_{k}^{T}Ap_{k}}$$\n",
    "\n",
    "$$\\beta_{k+1} = \\frac{r_{k+1}^{T}r_{k+1}}{r_{k}^{T}r_{k}} $$\n",
    "\n",
    "#### Algorithm\n",
    "\n",
    "Given $x_{0}$;\n",
    "\n",
    "\n",
    "Set $r_{0} \\leftarrow Ax_{0}-b$, $p_{0} \\leftarrow -r_{0}$, $k\\leftarrow 0$;\n",
    "\n",
    "while $r_{k} \\neq 0$\n",
    "\n",
    "$$\\alpha_{k} \\leftarrow \\frac{r_{k}^{T}r_{k}}{p_{k}^{T}Ap_{k}} ;$$\n",
    "\n",
    "$$x_{k+1} \\leftarrow x_{k} + \\alpha_{k} p_{k} ;$$\n",
    "\n",
    "$$r_{k+1}\\leftarrow r_{k}+\\alpha_{k}Ap_{k};$$\n",
    "\n",
    "$$\\beta_{k+1} \\leftarrow \\frac{r_{k+1}^{T}r_{k+1}}{r_{k}^{T}r_{k}}$$\n",
    "\n",
    "$$p_{k+1} \\leftarrow -r_{k+1} + \\beta_{k+1}p_{k};$$\n",
    "\n",
    "$$k \\leftarrow k+1;$$\n",
    "\n",
    "end (while)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fuente: _Nocedal Jorge , Wright Stephen J., Numerical Optimization, Second Edition (2006) 101-133_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[3, 2, -1], [2, -1, 1], [-1, 1, -1]])\n",
    "b = np.array([1, -2, 0])\n",
    "x = np.array([-2, 9,11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -2,  0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cgm(A,b,x):\n",
    "    \"\"\"\n",
    "    input:\n",
    "            A: Coeficient matrix\n",
    "            b: solution vector\n",
    "            x: vector to be optimize\n",
    "        output:\n",
    "            x: optimiza vector\n",
    "    \"\"\"\n",
    "    r = np.dot(A,x)-b\n",
    "    p = -r\n",
    "    k = 0\n",
    "    #print(r)\n",
    "    \n",
    "    while True: \n",
    "    #np.linalg.norm(r) < 1e-8:\n",
    "    #k <4:\n",
    "    #np.linalg.norm(r) < 1e-16:\n",
    "    \n",
    "    #(r < 1e-17).all():\n",
    "        r_s = np.dot(np.transpose(r),r)\n",
    "        alpha_k = r_s/np.dot(np.transpose(p),np.dot(A,p))\n",
    "        \n",
    "        x = x + np.dot(alpha_k,p)\n",
    "        \n",
    "        r = r + np.dot(alpha_k, np.dot(A,p))\n",
    "        \n",
    "        beta = np.dot(np.transpose(r),r)/r_s\n",
    "        \n",
    "        p = -r + beta*p\n",
    "        \n",
    "        k = k+1\n",
    "        #print(x)\n",
    "        if np.linalg.norm(r) < 1e-10:\n",
    "            break\n",
    "        if k > 10:\n",
    "            break\n",
    "        #print(k)\n",
    "    \n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.,  9., 11.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgm(a,b,np.array([1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.,  9., 11.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.solve(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sol = cgm(a,b,np.array([1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.820297636185407e-15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(np.linalg.solve(a, b)-x_sol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
